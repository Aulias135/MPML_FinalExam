# -*- coding: utf-8 -*-
"""UAS_MPML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yuPRkuZgS7ArtpOXwJwaxGDLz9Ya5MIS
"""

import pandas as pd
import numpy as np

"""# **1. Dataset Selection and Exploration**"""

# Read data transactions
transaction = pd.read_csv('transactions.csv')
transaction.head()

# Check missing value
transaction.info()

# Checking Null or Missing data
transaction.isna().sum()

"""# **2. Prepocessing Data**"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder

# Encode categorical variables
label_encoder = LabelEncoder()
transaction['Sender Name'] = label_encoder.fit_transform(transaction['Sender Name'])
transaction['Sender UPI ID'] = label_encoder.fit_transform(transaction['Sender UPI ID'])
transaction['Receiver Name'] = label_encoder.fit_transform(transaction['Receiver Name'])
transaction['Receiver UPI ID'] = label_encoder.fit_transform(transaction['Receiver UPI ID'])
transaction['Status'] = label_encoder.fit_transform(transaction['Status'])

# Scale numerical features
scaler = StandardScaler()
transaction['Amount (INR)'] = scaler.fit_transform(transaction[['Amount (INR)']])

# Drop the original Timestamp and Transaction ID column
transaction.drop(columns=['Timestamp', 'Transaction ID'], inplace=True)

transaction.head()

# Statistik deskriptif
print(transaction.describe())

"""**Visualization transaction data**"""

import matplotlib.pyplot as plt
import seaborn as sns

# Distribution of Amounts
plt.figure(figsize=(10, 6))
sns.histplot(transaction['Amount (INR)'], bins=30, kde=True)
plt.title('Distribution of Transaction Amounts')
plt.xlabel('Amount (INR)')
plt.ylabel('Frequency')
plt.show()

# Status Proportions
status_counts = transaction['Status'].value_counts()

plt.figure(figsize=(8, 8))
plt.pie(status_counts, labels=status_counts.index, autopct='%1.1f%%', startangle=140)
plt.title('Proportion of Transaction Statuses')
plt.show()

"""# **3.  Model Training and Comparison**"""

# Define features and target variable
X = transaction.drop(columns=['Status'])
y = transaction['Status']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

X_train

X_test

y_train

y_test

"""# **Logistic Regression**"""

# Normalisasi fitur
scaler = StandardScaler()
x_train = scaler.fit_transform(X_train)
x_test = scaler.transform(X_test)

from sklearn.linear_model import LogisticRegression
from sklearn import metrics
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix


# Train the model on the training set
logreg = LogisticRegression()
logreg.fit(X_train, y_train)

# Instantiate the model (using the default parameters)
logreg = LogisticRegression()

# fit the model with data
logreg.fit(x_test, y_test)

# predict the response values for the observations in X
logreg.predict(x_test)

# store the predicted response values
y_pred_logreg = logreg.predict(x_test)

# check how many predictions were generated
len(y_pred_logreg)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred_logreg)
report = classification_report(y_test, y_pred_logreg)
conf_matrix = confusion_matrix(y_test, y_pred_logreg)

print(f'Logistic Regression Accuracy: {accuracy}')
print('Classification Report:')
print(report)
print('Confusion Matrix:')
print(conf_matrix)

"""# **KNN**"""

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)
print(metrics.accuracy_score(y_test, y_pred_knn))

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred_knn)
report = classification_report(y_test, y_pred_knn)
conf_matrix = confusion_matrix(y_test, y_pred_knn)

print(f'KNN Accuracy: {accuracy}')
print('Classification Report:')
print(report)
print('Confusion Matrix:')
print(conf_matrix)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Evaluate the model using regression metrics
mae = mean_absolute_error(y_test, y_pred_knn)
mse = mean_squared_error(y_test, y_pred_knn)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred_knn)

# Print the evaluation metrics
print(f'Mean Absolute Error (MAE): {mae}')
print(f'Mean Squared Error (MSE): {mse}')
print(f'Root Mean Squared Error (RMSE): {rmse}')
print(f'R-squared (R²): {r2}')

"""# **SVM**"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix
from sklearn import svm
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train the SVM model
svm_model = SVC(kernel='linear', probability=True)
svm_model.fit(X_train_scaled, y_train)

# Make predictions
y_pred_svm = svm_model.predict(X_test_scaled)

y_pred_svm

# Evaluate the model
svm_accuracy = accuracy_score(y_test, y_pred_svm)
conf_matrix = confusion_matrix(y_test, y_pred_svm)
class_report = classification_report(y_test, y_pred_svm)

print(f"SVM Accuracy: {svm_accuracy}")
print("Confusion Matrix:")
print(conf_matrix)
print("Classification Report:")
print(class_report)

# Evaluate the model using regression metrics
mae = mean_absolute_error(y_test, y_pred_svm)
mse = mean_squared_error(y_test, y_pred_svm)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred_svm)

# Print the evaluation metrics
print(f'Mean Absolute Error (MAE): {mae}')
print(f'Mean Squared Error (MSE): {mse}')
print(f'Root Mean Squared Error (RMSE): {rmse}')
print(f'R-squared (R²): {r2}')

import numpy as np
import matplotlib.pyplot as plt

# Convert y_train to a NumPy array
y_train_array = np.array(y_train)

# Predict on the training data
y_train_pred = svm_model.predict(X_train_scaled)

# Plot predictions vs actual values
plt.figure(figsize=(10, 6))
plt.scatter(y_train_array, y_train_pred, color='blue', edgecolor='k', alpha=0.6)
plt.plot([y_train_array.min(), y_train_array.max()], [y_train_array.min(), y_train_array.max()], 'k--', lw=2)
plt.xlabel("Actual Status")
plt.ylabel("Predicted Status")
plt.title("Actual vs Predicted Status (Training Set)")
plt.show()

"""**Review of parameter tuning using cross_val_score**"""

from sklearn.model_selection import cross_val_score

"""**Logistic Regression**"""

# Logistic Regression
logreg_scores = cross_val_score(LogisticRegression(), X, y, cv=5)
print("Logistic Regression CV Accuracy:", logreg_scores.mean())

"""**KNN**"""

# Instantiate model
knn = KNeighborsClassifier(n_neighbors=5)

# Cross_val_score takes care of splitting X and y into the 10 folds that's why we pass X and y entirely instead of X_train and y_train
knn_scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')
print(knn_scores)

# Scores is a numpy array so we can use the mean method
print(knn_scores.mean())

"""**SVM**"""

svm_accuracy = accuracy_score(y_test, y_pred_svm)
print(svm_accuracy)

"""**Plot Compare Model**"""

# Visualzation
import matplotlib.pyplot as plt

# Cross-validation scores
models = ['Logistic Regression', 'KNN', 'SVM']
scores = [logreg_scores.mean(), knn_scores.mean() ,svm_accuracy]

plt.figure(figsize=(10, 6))
plt.bar(models, scores, color=['#5aa9e6', '#7fc8f8', '#bbdefb'])
plt.xlabel('Model')
plt.ylabel('Cross-Validation Accuracy')
plt.title('Model Performance Comparison')
plt.ylim(0, 1)
plt.show()

"""# **4. Model Selection and Deployment**

Berdasarkan metrik performa,model yang akan dipilih adalah Logistic Regression Model. Alasan memilih model ini karena berdasarkan hasil evaluasi model biasa (0.5366666666666666) dan menggunakan crossvalidation score (0.5189999999999999) serta melihat F1 scorenya model Regresi Logistik lebih tinggi dibandingkan model KNN dan SVM. Selain itu model Regresi Logistik termasuk model yang sederhana dan lebih dapat dengan mudah diinterpretasikan.
"""

